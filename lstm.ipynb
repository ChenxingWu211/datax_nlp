{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tried to estimate the lstm of paper, but the accuracy is lower than expected\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "#nltk.download('all')\n",
    "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pmid-pdf.json','r',encoding='UTF-8') as f:data_full = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('training.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['randomized', 'trial', 'randomization', 'controlled', 'placebo', 'trials', 'group', 'baseline', 'intervention', 'double', 'study', 'dose', 'design', 'studies', 'treatment', 'search', 'effect', 'week', 'published', 'participants', 'primary', 'center', 'assigned', 'received', 'outcome', 'included', 'inclusion', 'clinical', 'end', 'using', 'groups', 'prior', 'eligible', 'used', 'one', 'analysis', 'patients', 'visit', 'informed', 'day', 'mg', 'administered', 'days', 'randomly', 'criteria', 'weeks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['pmid','flag','method']\n",
    "new_df = pd.DataFrame(columns=columns)\n",
    "randome = ['randomiz']\n",
    "nonrandome = ['non-random','nonrandom']\n",
    "randome_count = 0\n",
    "nonrandome_count = 0\n",
    "randome_count_1 = 0\n",
    "nonrandome_count_1 = 0\n",
    "randome_count_2 = 0\n",
    "nonrandome_count_2 = 0\n",
    "flag = 0\n",
    "k=0\n",
    "p1 = 1\n",
    "p2 = 1000\n",
    "p= 0\n",
    "use_key_words = 0 # if the feature key words are used to select sentences \n",
    "for i in range(len(df)):\n",
    "    if (i % 500 == 0):\n",
    "        print(\"processed ..\", i)\n",
    "    pmid = df['pmid'][i]\n",
    "    body = df['body'][i]\n",
    "    method = ''\n",
    "    method_comp = ''\n",
    "    full_body = ''\n",
    "    randome_flag = 0\n",
    "    nonrandome_flag = 0\n",
    "    randome_flag_1 = 0\n",
    "    flag = 0\n",
    "    for j in range(len(body)):\n",
    "        temp = body[j]\n",
    "        full_body = full_body + \"\\n\" + temp['content']\n",
    "        if (re.search('method',temp['header'],re.I)):\n",
    "            method = method + temp['content'] + \" \"\n",
    "    if not method:\n",
    "        continue\n",
    "    # fetch only sentences in method with top feature words\n",
    "    if use_key_words == 1:\n",
    "        sentence = []\n",
    "        sentence = method.split(\".\")\n",
    "        for m in range(len(sentence)):\n",
    "            for n in range(len(features)):\n",
    "                if re.search(features[n],sentence[m],re.I):\n",
    "                    method_comp = method_comp + sentence[m] + \".\"\n",
    "                    break\n",
    "        if not method_comp:\n",
    "            continue\n",
    "        method = method_comp\n",
    "    abstract = str(df['_abstract'][i])\n",
    "    title = df['title'][i]\n",
    "    for j in range(len(randome)):\n",
    "        my_re1 = r\"^\" + re.escape(randome[j])\n",
    "        my_re2 = r\" \" + re.escape(randome[j])\n",
    "        if (re.search(my_re1,method,re.I) or re.search(my_re2,method,re.I)):\n",
    "            randome_count = randome_count + 1\n",
    "            randome_flag = 1\n",
    "            randome_flag_1 = 1\n",
    "        if (re.search(my_re1,abstract,re.I) or re.search(my_re2,abstract,re.I)):\n",
    "            randome_flag_1 = 1\n",
    "        if (re.search(my_re1,full_body,re.I) or re.search(my_re2,full_body,re.I)):\n",
    "            randome_flag_1 = 1        \n",
    "    for j in range(len(nonrandome)):\n",
    "        my_re = nonrandome[j]\n",
    "        if (re.search(my_re,method,re.I)):\n",
    "            nonrandome_count = nonrandome_count + 1\n",
    "            nonrandome_flag = 1\n",
    "        #if (re.search(my_re,abstract,re.I)):\n",
    "        #    nonrandome_count_1 = nonrandome_count_1 + 1\n",
    "        #    nonrandome_flag = 1\n",
    "        #if (re.search(my_re,full_body,re.I)):\n",
    "        #    nonrandome_count_2 = nonrandome_count_2 + 1\n",
    "        #    nonrandome_flag = 1\n",
    "    if (randome_flag == 1 and nonrandome_flag != 1):\n",
    "        flag = 1\n",
    "        new_df.loc[k] = [pmid,flag,method]\n",
    "        k=k+1\n",
    "    elif (nonrandome_flag == 1 or randome_flag_1 != 1):\n",
    "        flag = 0\n",
    "        p=p+1\n",
    "        if p >= p1 and p <= p2:\n",
    "            new_df.loc[k] = [pmid,flag,method]\n",
    "            k=k+1\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df['method'][1847])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWords = []\n",
    "for i in range(len(new_df)):\n",
    "    numWords.append(len(new_df['method'][i].split()))\n",
    "%matplotlib inline\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1000, 0, 300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 500\n",
    "numFiles = len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "def review_cleaner(review,lemmatize=False,stem=False):\n",
    "    '''\n",
    "    Clean and preprocess a review.\n",
    "\n",
    "    1. Use regex to remove all special characters (only keep letters)\n",
    "    2. Make strings to lower case and tokenize / word split reviews\n",
    "    3. Remove English stopwords\n",
    "    4. Rejoin to one string\n",
    "    '''\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    cleaned_review=''\n",
    "    #1. Remove punctuation\n",
    "    review = re.sub(\"[^a-zA-Z0-9]\", \" \",review)\n",
    "    \n",
    "    #2. Tokenize into words (all lower case)\n",
    "    review = review.lower().split()\n",
    "\n",
    "    #3. Remove stopwords\n",
    "            \n",
    "    clean_review=[]\n",
    "    for word in review:\n",
    "        if word not in eng_stopwords:\n",
    "            if lemmatize is True:\n",
    "                word=wnl.lemmatize(word)\n",
    "            elif stem is True:\n",
    "                if word == 'oed':\n",
    "                    continue\n",
    "                word=ps.stem(word)\n",
    "            clean_review.append(word)\n",
    "\n",
    "    #6. Join the review to one sentence    \n",
    "    review_processed = ' '.join(clean_review)\n",
    "    return(review_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for i in range(len(new_df)):\n",
    "    indexCounter = 0\n",
    "    line=new_df['method'][i]\n",
    "    cleanedLine = review_cleaner(line,lemmatize=False,stem=False)\n",
    "    split = cleanedLine.split()\n",
    "    for word in split:\n",
    "        try:\n",
    "            ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1\n",
    "    if (fileCounter % 100 == 0):\n",
    "        print(\"loaded ..\", fileCounter, \"files\")\n",
    "np.save('idsMatrix', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.load('idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC testing an example\n",
    "print(wordsList.index('randomized'))\n",
    "print(ids[1800][0:20])\n",
    "print(new_df['flag'][1800])\n",
    "method = review_cleaner(new_df['method'][1800],lemmatize=False,stem=False)\n",
    "print(method)\n",
    "split = method.split()\n",
    "for word in split:\n",
    "    try:\n",
    "        print(wordsList.index(word))\n",
    "    except ValueError:\n",
    "        print('399999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 72 # changing to 96 or 48, performance is worse\n",
    "lstmUnits = 64 # number of hidden layers, 96 similar/overfitting/flutuat, 48 is worse\n",
    "numClasses = 2 # convert the classic 1/0 boolean to two columnes (1,0) (0,1)\n",
    "iterations = 1000\n",
    "learning_rate = 0.001 # default is 0.001, if loss is unstable, decrease. if decrease is too slow, increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "size=len(new_df)\n",
    "new_df['reverse'] = 1- new_df['flag'].values\n",
    "y=new_df[['flag','reverse']].values.reshape(size,2) #astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(ids, y, random_state=0, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numDimensions = 50 # 50-300, change it to 100 does not improve performance\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.95)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainBatch(cycle):\n",
    "    max_cycle=int(np.floor(len(y_train)/batchSize))\n",
    "    new_cycle = int(cycle%max_cycle)\n",
    "    start = new_cycle*batchSize\n",
    "    end = start + batchSize\n",
    "    nlabels = y_train[start:end]\n",
    "    arr = X_train[start:end]\n",
    "    return arr, nlabels\n",
    "\n",
    "def getTestBatch(cycle):\n",
    "    max_cycle=int(np.floor(len(y_test)/batchSize))\n",
    "    start = int(cycle%max_cycle*batchSize)\n",
    "    end = start + batchSize\n",
    "    nlabels = y_test[start:end]\n",
    "    arr = X_test[start:end]\n",
    "    return arr, nlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "    #Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch(i)\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "    #Write summary to Tensorboard\n",
    "    if (i % 10 == 0):\n",
    "        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    #Save the network every 100 training iterations\n",
    "    if (i % 100 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch(i);\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n",
    "    print(\"Prediction:\", (sess.run(tf.argmax(prediction,1), {input_data: nextBatch, labels: nextBatchLabels})))\n",
    "    print(\"Labels:\", (sess.run(tf.argmax(labels,1), {input_data: nextBatch, labels: nextBatchLabels})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
